{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import beta\n",
    "from scipy.special import digamma\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, root_mean_squared_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from RMSProp import SGD_RMSProp\n",
    "from BetaRegression import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка SGD RMSProp на данных в модели бета-регрессии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_id</th>\n",
       "      <th>Visit_id</th>\n",
       "      <th>Species_id</th>\n",
       "      <th>Cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>6345</td>\n",
       "      <td>2338</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>16199</td>\n",
       "      <td>2338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>28382</td>\n",
       "      <td>2338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40703</td>\n",
       "      <td>2338</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>49283</td>\n",
       "      <td>2338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_id  Visit_id  Species_id  Cover\n",
       "0        4      6345        2338      2\n",
       "1        4     16199        2338      3\n",
       "2        4     28382        2338      3\n",
       "3        4     40703        2338      2\n",
       "4        4     49283        2338      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/observations.csv\", sep=\";\").drop(\"Cover_class\", axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"Cover\", axis=1), df[\"Cover\"] / 100\n",
    "colnames = df.columns.to_list()\n",
    "nrow, ncol = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_train_ones = np.hstack([X_train_s, np.ones((y_train.size, 1))])\n",
    "X_test_ones = np.hstack([X_test_s, np.ones((y_test.size, 1))])\n",
    "\n",
    "np.savetxt(\n",
    "    \"./Data/train.csv\",\n",
    "    np.hstack([X_train_s, y_train.to_numpy().reshape((y_train.size, 1))]),\n",
    "    comments=\"\",\n",
    "    delimiter=\",\",\n",
    "    header=\",\".join(colnames),\n",
    ")\n",
    "np.savetxt(\n",
    "    \"./Data/test.csv\",\n",
    "    np.hstack([X_test_s, y_test.to_numpy().reshape(y_test.size, 1)]),\n",
    "    comments=\"\",\n",
    "    delimiter=\",\",\n",
    "    header=\",\".join(colnames),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бета-регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 332 ms, sys: 940 μs, total: 333 ms\n",
      "Wall time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "mean_y_train = y_train.mean()\n",
    "phi_y_train = (mean_y_train * (1 - mean_y_train)) / y_train.var() - 1\n",
    "\n",
    "beta_start = normal(0, 1, 4)\n",
    "phi_start = phi_y_train\n",
    "start_point = np.append(beta_start, phi_start)\n",
    "\n",
    "beta_res = SGD_RMSProp(\n",
    "    start=start_point,\n",
    "    X=X_train_ones,\n",
    "    y=y_train.to_numpy(),\n",
    "    L_grad=beta_illh_grad,\n",
    "    L=beta_inv_log_likelihood,\n",
    "    batch_size=100,\n",
    "    use_epoch = True,\n",
    "    learning_rate=0.01,\n",
    "    decay_rate=0.9,\n",
    "    max_iter=5000,\n",
    "    tol=1e-8,\n",
    "    link_inverse=logit_inverse,\n",
    "    link_deriv=logit_deriv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "coef: [ 5.07145189e-03 -1.18579454e-03 -2.44834722e-01 -1.69638061e+00]\n",
      "phi: 3.2234246308237164\n",
      "loss function value: -4694.936478948099\n",
      "iteratons: 3652\n"
     ]
    }
   ],
   "source": [
    "beta_coef_est = beta_res[\"point\"][:-1]\n",
    "beta_phi_est = beta_res[\"point\"][-1]\n",
    "beta_loss = beta_res[\"L_value\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "coef: {beta_coef_est}\n",
    "phi: {beta_phi_est}\n",
    "loss function value: {beta_loss}\n",
    "iteratons: {beta_res[\"iterations\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициенты и минус логарифм функции правдоподобия для них, полученные функцией `betareg` в R\n",
    "Параметры оптимизации в `betareg` взяты по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [ 0.00422392 -0.00911975 -0.2439333  -1.668232  ]\n",
      "phi: 3.152048\n",
      "loss function value: -4693.874211280123\n"
     ]
    }
   ],
   "source": [
    "betareg_params = np.loadtxt(\"betareg_res.dat\", delimiter=\" \", unpack=False)\n",
    "betareg_coef_est = betareg_params[:-1]\n",
    "betareg_phi_est = betareg_params[-1]\n",
    "betareg_loss = beta_inv_log_likelihood(betareg_params, X_train_ones, y_train, link_inverse=logit_inverse)\n",
    "\n",
    "print(f\"\"\"coef: {betareg_coef_est}\n",
    "phi: {betareg_phi_est}\n",
    "loss function value: {betareg_loss}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_loss(w, X, y):\n",
    "    return norm(X.dot(w) - y) ** 2 / y.size\n",
    "\n",
    "\n",
    "def linear_loss_grad(w, X, y):\n",
    "    return 2 * X.T.dot(X.dot(w) - y) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "coef: [ 0.00199334  0.00013956 -0.06366348]\n",
      "intercept: 0.13845756109721372\n",
      "loss function value: 0.03973629802238174\n",
      "iteratons: 473\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "start_point_linear = normal(0, 1, 4)\n",
    "\n",
    "linear_res = SGD_RMSProp(\n",
    "    start=start_point_linear,\n",
    "    X=X_train_ones,\n",
    "    y=y_train.to_numpy(),\n",
    "    L_grad=linear_loss_grad,\n",
    "    L=linear_loss,\n",
    "    batch_size=0.1,\n",
    "    use_epoch = True,\n",
    "    learning_rate=0.01,\n",
    "    decay_rate=0.9,\n",
    "    max_iter=1000,\n",
    "    tol=1e-7\n",
    ")\n",
    "\n",
    "my_lin_coef_est = linear_res[\"point\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "coef: {my_lin_coef_est[:-1]}\n",
    "intercept: {my_lin_coef_est[-1]}\n",
    "loss function value: {linear_res[\"L_value\"]}\n",
    "iteratons: {linear_res[\"iterations\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия из библиотеки `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "coef: [ 0.00182775 -0.0001474  -0.06406937]\n",
      "intercept: 0.13737261573129636\n",
      "loss function value: 0.039734865602112576\n"
     ]
    }
   ],
   "source": [
    "sk_lin_model = SGDRegressor(alpha=0, learning_rate=\"adaptive\", eta0=0.01, max_iter=1000, tol=1e-7, random_state=42)\n",
    "sk_lin_model.fit(X_train_s, y_train)\n",
    "\n",
    "sk_lin_loss = linear_loss(np.append(sk_lin_model.coef_, sk_lin_model.intercept_), X_train_ones, y_train)\n",
    "sk_lin_coef_est = np.append(sk_lin_model.coef_, sk_lin_model.intercept_[0])\n",
    "print(f\"\"\"\n",
    "coef: {sk_lin_coef_est[:-1]}\n",
    "intercept: {sk_lin_coef_est[-1]}\n",
    "loss function value: {sk_lin_loss}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества моделей\n",
    "\n",
    "### Метрики:\n",
    "0.  **$\\boldsymbol{R^2}$**\n",
    "\n",
    "0. **BIC**:\n",
    "    $$ \\mathrm{BIC} = k \\log(n) - 2 \\log(L_m), $$\n",
    "    где $k$ - число оценённых параметров модели, $n$ - число индивидов, на которых \n",
    "    тренировалась модель, $L_m$ - функция правдоподобия модели.\n",
    "\n",
    "0.  **RMSE**:\n",
    "    $$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - y_i^*)^2}, $$\n",
    "    где $y_i$ - значение признака, $y_i^*$ - его предсказание по модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания моделей на тренировочной выборке\n",
    "beta_means_pred_train = logit_inverse(X_train_ones, beta_coef_est)\n",
    "betareg_means_pred_train = logit_inverse(X_train_ones, betareg_coef_est)\n",
    "sk_lin_pred_train = sk_lin_model.predict(X_train_s)\n",
    "my_lin_pred_train = X_train_ones.dot(my_lin_coef_est)\n",
    "\n",
    "# Предсказания моделей на тестовой выборке\n",
    "beta_means_pred_test = logit_inverse(X_test_ones, beta_coef_est)\n",
    "betareg_means_pred_test = logit_inverse(X_test_ones, betareg_coef_est)\n",
    "sk_lin_pred_test = sk_lin_model.predict(X_test_s)\n",
    "my_lin_pred_test = X_test_ones.dot(my_lin_coef_est)\n",
    "\n",
    "# Предсказания дисперсий на тренировочной выборки для моделей бета-регрессии\n",
    "beta_var_pred_train = beta_means_pred_train * (1 - beta_means_pred_train) / (1 + beta_phi_est)\n",
    "betareg_var_pred_train = betareg_means_pred_train * (1 - betareg_means_pred_train) / (1 + betareg_phi_est)\n",
    "\n",
    "# Предсказания дисперсий на тестовой выборки для моделей бета-регрессии\n",
    "beta_var_pred_test = beta_means_pred_test * (1 - beta_means_pred_test) / (1 + beta_phi_est)\n",
    "betareg_var_pred_test = betareg_means_pred_test * (1 - betareg_means_pred_test) / (1 + betareg_phi_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train data\n",
      "My linear model: R^2 = 0.09439019528454273\n",
      "Sklearn linear model: R^2 = 0.09442284084803865\n",
      "My beta regression model: R^2 = 0.05815304765210738\n",
      "R beta regression model: R^2 = 0.05511436981457207\n",
      "\n",
      "On test data\n",
      "My linear model: R^2 = 0.0944780291202536\n",
      "Sklearn linear model: R^2 = 0.09432311468456755\n",
      "My beta regression model: R^2 = 0.06113140899528602\n",
      "R beta regression model: R^2 = 0.058724747087445794\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"On train data\n",
    "My linear model: R^2 = {r2_score(y_train, my_lin_pred_train)}\n",
    "Sklearn linear model: R^2 = {r2_score(y_train, sk_lin_pred_train)}\n",
    "My beta regression model: R^2 = {r2_score(y_train, beta_means_pred_train)}\n",
    "R beta regression model: R^2 = {r2_score(y_train, betareg_means_pred_train)}\n",
    "\\nOn test data\n",
    "My linear model: R^2 = {r2_score(y_test, my_lin_pred_test)}\n",
    "Sklearn linear model: R^2 = {r2_score(y_test, sk_lin_pred_test)}\n",
    "My beta regression model: R^2 = {r2_score(y_test, beta_means_pred_test)}\n",
    "R beta regression model: R^2 = {r2_score(y_test, betareg_means_pred_test)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_log_likelihood(y_pred, y_test, k):\n",
    "    n = y_pred.size\n",
    "    sse = np.sum((y_pred - y_test) ** 2)\n",
    "    s2 = sse / (n - k)\n",
    "    return -n / 2 * np.log(2 * np.pi) - n / 2 * np.log(s2) - sse / (2 * s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train data\n",
      "My linear model: BIC = -1657.7510184970834\n",
      "Sklearn linear model: BIC = -1657.9090925102028\n",
      "My beta regression: BIC = -9347.943233372165\n",
      "R beta regression: BIC = -9345.818698036213\n",
      "\n",
      "\n",
      "On test data\n",
      "My linear model: BIC = -744.5652646998458\n",
      "Sklearn linear model: BIC = -744.1955978405847\n",
      "My beta regression: BIC = -4499.347695369185\n",
      "R beta regression: BIC = -4500.50457601093\n"
     ]
    }
   ],
   "source": [
    "train_n = X_train.shape[0]\n",
    "test_n = X_test.shape[0]\n",
    "\n",
    "lin_k = my_lin_coef_est.size + 1\n",
    "beta_k = beta_res[\"point\"].size\n",
    "\n",
    "my_lin_bic_train = lin_k * np.log(train_n) - 2 * linear_log_likelihood(X_train_ones.dot(my_lin_coef_est), y_train, lin_k)\n",
    "sk_lin_bic_train = lin_k * np.log(train_n) - 2 * linear_log_likelihood(X_train_ones.dot(sk_lin_coef_est), y_train, lin_k)\n",
    "beta_bic_train = beta_k * np.log(train_n) + 2 * beta_loss\n",
    "betareg_bic_train = beta_k * np.log(train_n) + 2 * betareg_loss\n",
    "print(f\"\"\"On train data\n",
    "My linear model: BIC = {my_lin_bic_train}\n",
    "Sklearn linear model: BIC = {sk_lin_bic_train}\n",
    "My beta regression: BIC = {beta_bic_train}\n",
    "R beta regression: BIC = {betareg_bic_train}\n",
    "\"\"\")\n",
    "\n",
    "my_lin_bic_test = lin_k * np.log(test_n) - 2 * linear_log_likelihood(X_test_ones.dot(my_lin_coef_est), y_test, lin_k)\n",
    "sk_lin_bic_test = lin_k * np.log(test_n) - 2 * linear_log_likelihood(X_test_ones.dot(sk_lin_coef_est), y_test, lin_k)\n",
    "beta_bic_test = beta_k * np.log(test_n) + 2 * beta_inv_log_likelihood(beta_res[\"point\"], X_test_ones, y_test, logit_inverse)\n",
    "betareg_bic_test = beta_k * np.log(test_n) + 2 * beta_inv_log_likelihood(betareg_params, X_test_ones, y_test, logit_inverse)\n",
    "\n",
    "print(f\"\"\"\\nOn test data\n",
    "My linear model: BIC = {my_lin_bic_test}\n",
    "Sklearn linear model: BIC = {sk_lin_bic_test}\n",
    "My beta regression: BIC = {beta_bic_test}\n",
    "R beta regression: BIC = {betareg_bic_test}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train data\n",
      "My linear model: RMSE = 0.19933965491688202\n",
      "Sklearn linear model: RMSE = 0.19933606197101542\n",
      "My beta regression: RMSE = 0.2032887346262716\n",
      "R beta regression: RMSE = 0.20361640544840412\n",
      "\n",
      "On test data\n",
      "My linear model: RMSE = 0.20187713133401008\n",
      "Sklearn linear model: RMSE = 0.20189439891306546\n",
      "My beta regression: RMSE = 0.2055606744303\n",
      "R beta regression: RMSE = 0.2058239692202449\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"On train data\n",
    "My linear model: RMSE = {root_mean_squared_error(y_train, my_lin_pred_train)}\n",
    "Sklearn linear model: RMSE = {root_mean_squared_error(y_train, sk_lin_pred_train)}\n",
    "My beta regression: RMSE = {root_mean_squared_error(y_train, beta_means_pred_train)}\n",
    "R beta regression: RMSE = {root_mean_squared_error(y_train, betareg_means_pred_train)}\n",
    "\\nOn test data\n",
    "My linear model: RMSE = {root_mean_squared_error(y_test, my_lin_pred_test)}\n",
    "Sklearn linear model: RMSE = {root_mean_squared_error(y_test, sk_lin_pred_test)}\n",
    "My beta regression: RMSE = {root_mean_squared_error(y_test, beta_means_pred_test)}\n",
    "R beta regression: RMSE = {root_mean_squared_error(y_test, betareg_means_pred_test)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение остатков Пирсона модели бета регрессии на тестовой выборке (стандартизованы с учётом гетероскедастичности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of residuals: -0.11337939991032248\n",
      "Variance of residuals: 1.2549317333340915\n",
      "Quantiles of residuals: [-0.90229075 -0.83821511 -0.57767217  0.02081175  4.23086114]\n"
     ]
    }
   ],
   "source": [
    "beta_resids = y_test - beta_means_pred_test\n",
    "beta_resids_pearson = beta_resids / np.sqrt(beta_var_pred_test)\n",
    "\n",
    "print(f\"\"\"Mean of residuals: {beta_resids_pearson.mean()}\n",
    "Variance of residuals: {beta_resids_pearson.var()}\n",
    "Quantiles of residuals: {np.quantile(beta_resids_pearson, [0, 0.25, 0.5, 0.75, 1])}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
